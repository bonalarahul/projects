{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# objective\n",
    "    The Project contains data of stack-overflow-developers.Data like developers experience,employment status,job     satisfaction,career satisfaction & Salary etc.\n",
    "    project's objective is to predict whether a person will opt to contribute for an open source projet or not.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/stack-overflow-2018-developer-survey/survey_results_public.csv\n",
      "/kaggle/input/stack-overflow-2018-developer-survey/survey_results_schema.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Importing libraries\n",
    "     Numpy and panda libraries has a lot of predefined functions that will be essential \n",
    "     for us in project\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. # Importing Dataframe\n",
    "Here we are importing datasets in to our notebook from Kaggle data sets repository  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (8,12,13,14,15,16,50,51,52,53,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dataset=pd.read_csv('/kaggle/input/stack-overflow-2018-developer-survey/survey_results_public.csv')\n",
    "dataset2=pd.read_csv('/kaggle/input/stack-overflow-2018-developer-survey/survey_results_schema.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigning first 17 columns of dataframe to a new data frame mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata=dataset.iloc[:,:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 98855 entries, 0 to 98854\n",
      "Data columns (total 17 columns):\n",
      "Respondent            98855 non-null int64\n",
      "Hobby                 98855 non-null object\n",
      "OpenSource            98855 non-null object\n",
      "Country               98443 non-null object\n",
      "Student               94901 non-null object\n",
      "Employment            95321 non-null object\n",
      "FormalEducation       94703 non-null object\n",
      "UndergradMajor        79036 non-null object\n",
      "CompanySize           71531 non-null object\n",
      "DevType               92098 non-null object\n",
      "YearsCoding           93835 non-null object\n",
      "YearsCodingProf       77903 non-null object\n",
      "JobSatisfaction       69276 non-null object\n",
      "CareerSatisfaction    76504 non-null object\n",
      "HopeFiveYears         75718 non-null object\n",
      "JobSearchStatus       79488 non-null object\n",
      "LastNewJob            78889 non-null object\n",
      "dtypes: int64(1), object(16)\n",
      "memory usage: 12.8+ MB\n"
     ]
    }
   ],
   "source": [
    "mydata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  As we can see our data has some null values\n",
    "# Below steps are to drop rows containing null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = mydata.dropna(axis=0, subset=['JobSatisfaction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = mydata.dropna(axis=0, subset=['Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = mydata.dropna(axis=0, subset=['Student'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = mydata.dropna(axis=0, subset=['Employment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = mydata.dropna(axis=0, subset=['FormalEducation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = mydata.dropna(axis=0, subset=['UndergradMajor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = mydata.dropna(axis=0, subset=['CompanySize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = mydata.dropna(axis=0, subset=['DevType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = mydata.dropna(axis=0, subset=['YearsCoding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = mydata.dropna(axis=0, subset=['YearsCodingProf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = mydata.dropna(axis=0, subset=['CareerSatisfaction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = mydata.dropna(axis=0, subset=['HopeFiveYears'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = mydata.dropna(axis=0, subset=['JobSearchStatus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = mydata.dropna(axis=0, subset=['LastNewJob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = mydata.dropna(axis=0, subset=['OpenSource'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Let us chechk if there are more null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 53050 entries, 0 to 71530\n",
      "Data columns (total 17 columns):\n",
      "Respondent            53050 non-null int64\n",
      "Hobby                 53050 non-null object\n",
      "OpenSource            53050 non-null object\n",
      "Country               53050 non-null object\n",
      "Student               53050 non-null object\n",
      "Employment            53050 non-null object\n",
      "FormalEducation       53050 non-null object\n",
      "UndergradMajor        53050 non-null object\n",
      "CompanySize           53050 non-null object\n",
      "DevType               53050 non-null object\n",
      "YearsCoding           53050 non-null object\n",
      "YearsCodingProf       53050 non-null object\n",
      "JobSatisfaction       53050 non-null object\n",
      "CareerSatisfaction    53050 non-null object\n",
      "HopeFiveYears         53050 non-null object\n",
      "JobSearchStatus       53050 non-null object\n",
      "LastNewJob            53050 non-null object\n",
      "dtypes: int64(1), object(16)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "mydata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Respondent            0\n",
       "Hobby                 0\n",
       "OpenSource            0\n",
       "Country               0\n",
       "Student               0\n",
       "Employment            0\n",
       "FormalEducation       0\n",
       "UndergradMajor        0\n",
       "CompanySize           0\n",
       "DevType               0\n",
       "YearsCoding           0\n",
       "YearsCodingProf       0\n",
       "JobSatisfaction       0\n",
       "CareerSatisfaction    0\n",
       "HopeFiveYears         0\n",
       "JobSearchStatus       0\n",
       "LastNewJob            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, we can see that thre are no more null values in dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating X with all independent variables and y with all dependent variables\n",
    "\n",
    "As I mentioned before, Our objective is to predict 'Yes' or 'No' for open source.\n",
    "So, y variable is Open_Source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(mydata.iloc[:,2])\n",
    "\n",
    "df=pd.DataFrame(mydata)\n",
    "X=df.drop(['OpenSource'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dummification\n",
    " Machine cannot understand Strings(Categorical Variables).So, a number should be assigned to every Strings(Catgorical Variable),Whenever this number occurs in that column, machine understands that respective String categorical variable has occured.This process of converting  Strings(categorical variables) in to numerical factors is called dummification.\n",
    " \n",
    " Below given steps are of dummification of X and y dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.get_dummies(X,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=pd.get_dummies(y, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitting data in to train and test sets\n",
    "We split the data set in to test and train data sets.We perform our model on train data set and test our model on test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(a,b,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* # Applying decision tree classifier on train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "regression=DecisionTreeClassifier()\n",
    "regression.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# performing prediction for test dataset\n",
    "  In next steps we perform prediction on Open_source for test data set and compare it with the actual Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating accuracy of our prediction\n",
    "In next steps we calcuate accuracy,Here accuracy is (no of correct predictions)/total no of observations.More the accuracy,better our model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3825, 2269],\n",
       "       [2322, 2194]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=sum(sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=(cm[0,0]+cm[1,1])/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5672950047125354"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got an accuracy of 56.3 percent i.e of all the predicted outputs, 56.3 are correct\n",
    "\n",
    "So, let us try random forest model and check the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Randomforestclassificaton on train dataset\n",
    "Below, we perform the same steps above but we are doing it for Random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randomclassifier=RandomForestClassifier(n_estimators=10,criterion='entropy',random_state=0)\n",
    "randomclassifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2=randomclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating accuracy of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm2=confusion_matrix(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4753, 1341],\n",
       "       [3046, 1470]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "total2=sum(sum(cm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy2=(cm2[0,0]+cm2[1,1])/total2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5865221489161169"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest model is giving us more accuracy(58.6%) than decision tree model(56.2%), but still this is not good enough.\n",
    "\n",
    "We can  make this model more accurate by removing the indpendent variables which does not gave much impact on depndent variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In next steps, We are trying to remove those columns which doesnot have much impact on our \n",
    "dependent variable(Open_Source). This helps in increasing accuracy of our prediction\n",
    "\n",
    "We are trying to check whether 'Country' and 'DevType' columns are significant or not because the no of distinct observtions in these two columns are far more when compared to other columns and if they are not affecting independent variables then we could get rid of thse two columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=[]\n",
    "z=0\n",
    "for i in range(187,5977):\n",
    "    k=X_train.columns[i]\n",
    "    for j in range(0,42440):\n",
    "     if(X_train[k].values[j]==1):\n",
    "        \n",
    "       if(y_train.iloc[j][0]==1):\n",
    "            m.append(True)\n",
    "       else:\n",
    "            m.append(False)\n",
    "            \n",
    "            \n",
    "    if(all(m)==any(m)):\n",
    "        print(i)\n",
    "        z=z+1\n",
    "            \n",
    "    \n",
    "        \n",
    "    \n",
    "          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=[]\n",
    "z=0\n",
    "for i in range(2,161):\n",
    "    k=X_train.columns[i]\n",
    "    for j in range(0,42440):\n",
    "     if(X_train[k].values[j]==1):\n",
    "        \n",
    "       if(y_train.iloc[j][0]==1):\n",
    "            m.append(True)\n",
    "       else:\n",
    "            m.append(False)\n",
    "            \n",
    "            \n",
    "    if(all(m)==any(m)):\n",
    "        print(i)\n",
    "        z=z+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking whether obsevations in \"DevType' and 'Country' are showing any impact on our dependent variable.\n",
    "we found out that both of these colums are not showing any impact on our dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In next steps, we remove all the dummy columns of dependent variables 'DevType' \n",
    "and 'Country' from train data set and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "X_train.drop(X_train.iloc[:,2:160],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(X_train.iloc[:,187:5976],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop(X_test.iloc[:,2:160],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop(X_test.iloc[:,187:5976],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In next steps we reiteerate the steps that we performed while calculating accuracy for decision tree model and Random foreest model.Only difference is we are prforming it on updated datasets, i.e dataset after removing columns 'DevType' and 'Country'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classification=DecisionTreeClassifier()\n",
    "classification.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y3_pred=classification.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm3=confusion_matrix(y_test,y3_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy3=(cm3[0,0]+cm3[1,1])/sum(sum(cm3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5317624882186617"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy we got for updated dataset is 52.9 which is less when compared to  56.2 i.e accuracy we got with first dataset\n",
    "\n",
    "Now, let us check Random forest on updated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randomclassifier2=RandomForestClassifier(n_estimators=10,criterion='entropy',random_state=0)\n",
    "randomclassifier2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4=randomclassifier2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm4=confusion_matrix(y_test,y_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy4=(cm4[0,0]+cm4[1,1])/sum(sum(cm4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5397737983034873"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of Random forest model on updated data set is 53.9 which is less than 58.6,i.e accuracy of Random forest model on first data set.\n",
    "\n",
    "As Accuracy of Random forest model on first data set is more.We Should predict our independent variable by performing Random forest model on first data set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
